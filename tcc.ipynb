{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc93280",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------ Importações gerais\n",
    "import pandas as pd\n",
    "from pandas.tseries.offsets import DateOffset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "import dateutil.relativedelta\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.metrics import r2_score, roc_auc_score, accuracy_score\n",
    "\n",
    "#import xgboost as xgb\n",
    "\n",
    "#from lightgbm import LGBMClassifier\n",
    "from sklearn import metrics\n",
    "pd.set_option('display.max_rows', 250)\n",
    "pd.set_option('display.max_columns', None)\n",
    "np.set_printoptions(suppress=True, precision=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbcd267f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------ Funções\n",
    "\n",
    "# Função para manipulação das datas\n",
    "def separa_datas(df, col):\n",
    "    temp = pd.DataFrame()\n",
    "    print('\\nResgatando informações do dataframe...')\n",
    "    temp[col] = pd.to_datetime(df[col], format='%b-%Y')\n",
    "#    dias = []  # cria lista vazia para ser preenchida com a informação dos dias\n",
    "    mes_ano = []  # cria lista vazia para ser preenchida com mês/ano\n",
    "\n",
    "    if temp[col].isnull().sum() > 0:\n",
    "        print(f'\\nATENÇÃO! Identificadas NaNs na feature {col}, impossível continuar.')\n",
    "        print(f'Favor resolver as {temp[col].isnull().sum()} NaNs antes de tentar novamente. Seu bosta.')\n",
    "    else:\n",
    "        print('\\nSeparando parâmetros de data e gerando nova série, só um instante por favor.')\n",
    "        for i in range(0, len(temp)):  # preenche a lista com mês e ano\n",
    "            mes_ano.append(temp.loc[i, col].strftime('%b-%Y').lower())\n",
    "        print('\\nTudo pronto.')\n",
    "\n",
    "        return pd.Series(data=mes_ano, name='mes_ano')  # retorna uma série nova\n",
    "\n",
    "\n",
    "# Função para buscar a explicação de cada feature no dicionário e analisar NaNs\n",
    "def analise_geral(lista, dataframe: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    :param lista: lista de features a se verificar\n",
    "    :dtype lista: list\n",
    "    :param dataframe: o banco de dados que contem todas as features que serão verificadas\n",
    "    :type dataframe: DataFrame\n",
    "    \"\"\"\n",
    "    def significado(x: object):\n",
    "        dic = pd.read_csv('./data/dictionary.csv', index_col=False)\n",
    "        print(f'Nome: {str(x).upper()}')\n",
    "        print(f'Definição: {dic[dic['Feature'] == str(x)]['Descrição'].values}')\n",
    "\n",
    "    if len(lista) > 1:\n",
    "        for i in range(0, len(lista)):\n",
    "            print('\\n')\n",
    "            print(f'Feature #{i+1}/{len(lista)}')\n",
    "            significado(lista[i])\n",
    "            print(f'Tipo de dado: {str(dataframe[lista[i]].dtypes).upper()}')\n",
    "            print(f'Quantidade total de NaNs: {dataframe[lista[i]].isnull().sum()}')\n",
    "            print(f'Proporção desses NaNs: {round((dataframe[lista[i]].isnull().sum()/len(dataframe))*100, 2)}%')\n",
    "    elif len(lista) == 1:\n",
    "        print('\\n')\n",
    "        significado(lista[0])\n",
    "        print(f'Tipo de dado: {str(dataframe[lista[0]].dtypes).upper()}')\n",
    "        print(f'Quantidade total de NaNs: {dataframe[lista[0]].isnull().sum()}')\n",
    "        print(f'Proporção desses NaNs: {round((dataframe[lista[0]].isnull().sum()/len(dataframe))*100, 2)}%')\n",
    "\n",
    "\n",
    "# Função que analisa apenas as features sem NaNs\n",
    "def analise_nans(lista, dataframe: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    :param lista: lista de features a se verificar\n",
    "    :dtype lista: list\n",
    "    :param dataframe: o banco de dados que contem todas as features que serão verificadas\n",
    "    :type dataframe: DataFrame\n",
    "    \"\"\"\n",
    "    def significado(x: object):\n",
    "        dic = pd.read_csv('./data/dictionary.csv', index_col=False)\n",
    "        print(f'Nome: {str(x).upper()}')\n",
    "        print(f'Definição: {dic[dic['Feature'] == str(x)]['Descrição'].values}')\n",
    "    print('\\nVerificando...')\n",
    "\n",
    "    if len(lista) > 1:\n",
    "        if any(dataframe[lista].isnull().sum() > 1) == False:\n",
    "            print('==> Sem NaNs nessa lista, parabéns.')\n",
    "        else:\n",
    "            print('Calculando tamanho da solicitação, só um instante por favor.')\n",
    "            tam = len(dataframe[lista].isnull().sum()[dataframe[lista].isnull().sum() > 0])\n",
    "            idx = 1\n",
    "            for i in range(0, len(lista)):\n",
    "                if dataframe[lista[i]].isnull().sum() == 0:\n",
    "                    pass\n",
    "                else:\n",
    "                    print('\\n')\n",
    "                    print(f'Feature #{idx}/{tam}')\n",
    "                    significado(lista[i])\n",
    "                    print(f'Tipo de dado: {str(dataframe[lista[i]].dtypes).upper()}')\n",
    "                    print(f'Quantidade total de NaNs: {dataframe[lista[i]].isnull().sum()}')\n",
    "                    print(f'Proporção desses NaNs: {round((dataframe[lista[i]].isnull().sum()/len(dataframe))*100, 2)}%')\n",
    "                    idx += 1\n",
    "    elif len(lista) == 1:\n",
    "        if dataframe[lista[0]].isnull().sum() == 0:\n",
    "            print('==> Sem NaNs nessa lista, parabéns.')\n",
    "        else:\n",
    "            print('\\n')\n",
    "            significado(lista[0])\n",
    "            print(f'Tipo de dado: {str(dataframe[lista[0]].dtypes).upper()}')\n",
    "            print(f'Quantidade total de NaNs: {dataframe[lista[0]].isnull().sum()}')\n",
    "            print(f'Proporção desses NaNs: {round((dataframe[lista[0]].isnull().sum()/len(dataframe))*100, 2)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c7bb91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA WRANGLING: INFORMAÇÕES DOS CONTRATOS\n",
    "#=========================\n",
    "\n",
    "# Leitura do arquivo com as informações dos contratos\n",
    "emprestimos = pd.read_csv('./data/loans2020.csv', low_memory=False) # hiperparâmetro 'low_memory' aqui apenas para não retornar aviso no console\n",
    "\n",
    "# Ajuste de duas features enquadradas como 'object' em função de notação percentual\n",
    "emprestimos['revol_util'] = emprestimos['revol_util'].str.replace('%', '').astype('float64')\n",
    "emprestimos['int_rate'] = emprestimos['int_rate'].str.replace('%', '').astype('float64')\n",
    "\n",
    "# Algumas observações em revol_util não estão corretas (cálculo revol_bal/total_rev_hi_lim). Empiricamente\n",
    "# a ocorrência de registros diferentes é de menos de 3% do total, então opta-se por recalcular toda a feature revol_util\n",
    "utilizado = emprestimos['revol_bal']\n",
    "total = emprestimos['total_rev_hi_lim']\n",
    "revol_util = utilizado/total\n",
    "emprestimos['revol_util'] = revol_util\n",
    "\n",
    "# A feature 'loan_status' contem as informações necessárias:\n",
    "# - Fully paid: empréstimos quitados\n",
    "# - Current: empréstimos ativos\n",
    "# - Charged off: empréstimos vencidos já reclassificados como prejuízo\n",
    "# - Late (31-120 days): empréstimos em atraso\n",
    "# - In Grace Period: empréstimos atrasados mas que ainda podem ser pagos sem ônus, neste estudo considera-se este enquadramento\n",
    "#                    como período entre 1-15 dias de atraso, dadas as demais características do banco de dados\n",
    "# - Late (16-30 days): empréstimos em atraso\n",
    "# - Does not meet the credit policy (ambos): descartados? não atendem a política de crédito - vai saber\n",
    "# - Default: empréstimos atrasados a mais de 120 dias mas ainda não enquadrados em prejuízo\n",
    "emprestimos['loan_status'].value_counts()\n",
    "\n",
    "# Esse estudo se propõe a analisar o risco de atraso de uma operação no tocante à questão de prejuízo à instituição financeira.\n",
    "# Para tanto, serão considerados os empréstimos cujos loan_status estejam enquadrados em default ou pior, pois assume-se que os\n",
    "# contratos que possuem atraso de até 120 dias possuam uma chance razoável de recebimento por parte da instituição, bem como na\n",
    "# literatura em inglês o estudado é o risco efetivo de default, não o risco de atraso.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7d144b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXPLORATORY DATA ANALYSIS (EDA)\n",
    "#=========================\n",
    "\n",
    "# Verificando as features com maiores % de valores NaN:\n",
    "# 29 features com NaNs acima de 90% do total de observações;\n",
    "# 35 acima de 50% das observações;\n",
    "# 35 acima de 40% das observações;\n",
    "# 37 acima de 30% das observações;\n",
    "# 49 acima de 29% das observações.\n",
    "# Para verificação:\n",
    "# len(emprestimos.isnull().sum()[emprestimos.isnull().sum()/emprestimos.shape[0] > 0.3])\n",
    "\n",
    "# Dada a alteração na quantidade de variáveis entre 37 e 40% de NaNs, opta-se por eliminar o menor número possível\n",
    "# entre essas duas, logo, as features com quantidade de NaNs equivalente a 40% ou mais das observações terão\n",
    "# atenção maior na tentativa de imputar valores faltantes\n",
    "feature_drop = emprestimos.isnull().sum()[emprestimos.isnull().sum()/emprestimos.shape[0] > 0.3].index.values\n",
    "\n",
    "# Análise individual de cada uma dessas features\n",
    "analise_geral(feature_drop, emprestimos)\n",
    "\n",
    "# Seleção das features de renegociação (15 variáveis no total)\n",
    "hard_cols = []\n",
    "hard_cols.append(feature_drop[34])  # essas três features não possuem 'hardship' no nome, então são\n",
    "hard_cols.append(feature_drop[30])  # inseridas manualmente\n",
    "hard_cols.append(feature_drop[26])\n",
    "for hardship in emprestimos.columns.to_list():\n",
    "    if \"hardship\" in hardship:\n",
    "        hard_cols.append(hardship)\n",
    "\n",
    "# Seleção das features de aplicação conjunta (15 variáveis)\n",
    "sep_ap = []\n",
    "for other_applicant in emprestimos.columns.to_list():\n",
    "    if \"sec_app_\" in other_applicant:\n",
    "        sep_ap.append(other_applicant)\n",
    "    if \"joint\" in other_applicant:\n",
    "        sep_ap.append(other_applicant)\n",
    "\n",
    "# Segregando features de aplicação conjunta e de renegociação\n",
    "joint_ap = emprestimos[sep_ap].copy()\n",
    "emprestimos.drop(sep_ap, axis=1, inplace=True)\n",
    "\n",
    "hardships = emprestimos[hard_cols].copy()\n",
    "emprestimos.drop(hard_cols, axis=1, inplace=True)\n",
    "\n",
    "# Salva as informações de forma individual em Parquet (mais rápido, menos espaço)\n",
    "#hardships.to_parquet('data/hardships.parquet')\n",
    "#joint_ap.to_parquet('data/joint_ap.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d89b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA WRANGLING: TRATAMENTO DOS CONTRATOS COM RENEGOCIAÇÃO\n",
    "#=========================\n",
    "hardships = pd.read_parquet('data/hardships.parquet')\n",
    "hard_cols = hardships.columns.to_list()\n",
    "\n",
    "# Relembrando cada uma das features\n",
    "analise_geral(hard_cols, hardships)\n",
    "\n",
    "# Parte-se do princípio que quem não tenha status definido de hardship é em função de não ter realizado acordo algum\n",
    "mask = hardships['hardship_loan_status'].isnull() == False\n",
    "\n",
    "# Criando feature nova identificando quais contratos tem renegociação\n",
    "hardships['fez_hardship'] = 0\n",
    "hardships.loc[mask, 'fez_hardship'] = 1\n",
    "\n",
    "# Verificação de NaNs dentro destes que fizeram hardship\n",
    "hardships.loc[mask].isnull().sum()[hardships.loc[mask].isnull().sum() > 0]\n",
    "\n",
    "# hardship_flag preenchendo com a moda ('N')\n",
    "hardships.loc[mask, 'hardship_flag'] = hardships.loc[mask, 'hardship_flag'].fillna('N')\n",
    "\n",
    "# hardship_status preenchendo com 'ACTIVE'\n",
    "hardships.loc[mask, 'hardship_status'] = hardships.loc[mask, 'hardship_status'].fillna('ACTIVE')\n",
    "\n",
    "# hardship_reason preenchendo com 'Unknown', não foi percebido padrão\n",
    "hardships.loc[mask, 'hardship_reason'] = hardships.loc[mask, 'hardship_reason'].fillna('UNKNOWN')\n",
    "\n",
    "# orig_projected_additional_accrued_interest preenchido com zero, em função de 'hardship_type'\n",
    "hardships.loc[mask, 'orig_projected_additional_accrued_interest'] = hardships.loc[mask, 'orig_projected_additional_accrued_interest'].fillna(0)\n",
    "\n",
    "\n",
    "# Todas as features com dtypes numéricos terão fillna(0).\n",
    "lista = hardships.dtypes[hardships.dtypes == 'float64'].index.to_list()\n",
    "hardships[lista] = hardships[lista].fillna(0)\n",
    "\n",
    "\n",
    "# Todas as features com dtypes categóricos terão fillna específico\n",
    "lista = hardships.dtypes[hardships.dtypes == 'object'].index.to_list()\n",
    "hardships['hardship_flag'] = hardships['hardship_flag'].fillna('N')  # não tem motivo por ter sido flaggado\n",
    "hardships[lista] = hardships[lista].fillna('Not Applicable')\n",
    "\n",
    "\n",
    "# A feature hardship_reason tem classes repetidas, com grafia diferente. De repente pode ser unido DISABILITY com MEDICAL também.\n",
    "# Ajuste abaixo.\n",
    "mask = hardships['hardship_reason'] == 'INCOMECURT'\n",
    "hardships.loc[mask, 'hardship_reason'] = 'INCOME_CURTAILMENT'\n",
    "\n",
    "mask = hardships['hardship_reason'] == 'UNEMPLOYED'\n",
    "hardships.loc[mask, 'hardship_reason'] = 'UNEMPLOYMENT'\n",
    "\n",
    "mask = hardships['hardship_reason'] == 'REDCDHOURS'\n",
    "hardships.loc[mask, 'hardship_reason'] = 'REDUCED_HOURS'\n",
    "\n",
    "mask = hardships['hardship_reason'] == 'NATDISAST'\n",
    "hardships.loc[mask, 'hardship_reason'] = 'NATURAL_DISASTER'\n",
    "\n",
    "mask = hardships['hardship_reason'] == 'EXCESSOBLI'\n",
    "hardships.loc[mask, 'hardship_reason'] = 'EXCESSIVE_OBLIGATIONS'\n",
    "\n",
    "mask = hardships['hardship_reason'] == 'FINANCIAL'  # Agregando 'financial' em 'excessive_obligations' pois, via de regra, tem a mesma causa\n",
    "hardships.loc[mask, 'hardship_reason'] = 'EXCESSIVE_OBLIGATIONS'\n",
    "\n",
    "mask = hardships['hardship_reason'] == 'DEATH'  # Agregando 'death' em 'family_death', deduz-se que o falecido não vai pedir renegociação do próprio contrato\n",
    "hardships.loc[mask, 'hardship_reason'] = 'FAMILY_DEATH'\n",
    "\n",
    "# Trabalhar com uppercase é desconfortável, ajustando:\n",
    "for i in range(0, len(lista)):\n",
    "    hardships[lista[i]] = hardships[lista[i]].str.lower()\n",
    "\n",
    "# Quando realizada a renegociação, o status dessa renegociação é que passará a ser o target do modelo. São consideradas operações\n",
    "# inadimplidas as com status 'incollection' (terceirizada), 'delinquent' (inadimplente), e 'issued' (registrada como inadimplida rumo a prejuízo)\n",
    "inad = ['incollection', 'delinquent', 'issued']\n",
    "# Criação do target:\n",
    "mask = hardships['hardship_loan_status'].isin(inad)  # máscara para identificação dos contratos não-pagos\n",
    "hardships['hardship_default'] = 0  # criação da feature de target\n",
    "hardships.loc[mask, 'hardship_default'] = 1  # registro dos contratos não-pagos\n",
    "hardships.drop('hardship_loan_status', axis=1, inplace=True)  # dropa a variável referência do target\n",
    "\n",
    "# Para a criação de novas variáveis contemplando os prazos de renegociação primeiro precisa-se transformar as features de\n",
    "# base em datetime[ns], para tanto os valores 'not applicable' serão substituídos pelo mês 'jan-2125' apenas como facilitador\n",
    "# do cálculo para depois ajustar esses valores corretamente\n",
    "feats = ['hardship_end_date', 'hardship_start_date', 'payment_plan_start_date']\n",
    "for feat in feats:\n",
    "    mask = hardships[feat] == 'not applicable'\n",
    "    hardships.loc[mask, feat] = 'jan-2125'\n",
    "    hardships[feat] = pd.to_datetime(hardships[feat], format='%b-%Y')\n",
    "\n",
    "# Criação de nova feature com o tempo total do contrato de renegociação\n",
    "anos = (hardships['hardship_end_date'].dt.year - hardships['hardship_start_date'].dt.year)*12\n",
    "meses = hardships['hardship_end_date'].dt.month - hardships['hardship_start_date'].dt.month\n",
    "tempo_contrato = anos + meses\n",
    "hardships['tempo_total_contrato'] = tempo_contrato\n",
    "\n",
    "# Criação de nova feature, de tempo total de de payment_plan\n",
    "anos = (hardships['hardship_end_date'].dt.year - hardships['payment_plan_start_date'].dt.year)*12\n",
    "meses = hardships['hardship_end_date'].dt.month - hardships['payment_plan_start_date'].dt.month\n",
    "tempo_payment = anos + meses\n",
    "hardships['tempo_payment_plan'] = tempo_payment\n",
    "\n",
    "# Colunas de data já utilizadas, pode-se dropar\n",
    "hardships.drop(feats, axis=1, inplace=True)\n",
    "\n",
    "# Salva alterações em disco\n",
    "#hardships.to_parquet('data/hardships_wrangled.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3725a192",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA WRANGLING: TRATAMENTO DOS CONTRATOS COM APLICAÇÃO CONJUNTA\n",
    "#=========================\n",
    "joint_ap = pd.read_parquet('data/joint_ap.parquet')\n",
    "sep_ap = joint_ap.columns.to_list()\n",
    "\n",
    "# Criação de indicador de contrato com composição de renda\n",
    "mask = joint_ap['annual_inc_joint'].isnull()\n",
    "joint_ap['contrato_conjunto'] = 0\n",
    "joint_ap.loc[~mask, 'contrato_conjunto'] = 1\n",
    "\n",
    "# Verificação dos dtypes 'object' primeiro:\n",
    "lista = joint_ap.dtypes[joint_ap.dtypes == 'object'].index.to_list()\n",
    "\n",
    "# As observações de 'verification_status_joint' (lista[0]) com NaN que foram\n",
    "# identificadas como contrato conjunto terão fillna('Not Verified')\n",
    "mask = joint_ap['contrato_conjunto'] == 1\n",
    "\n",
    "# Preenche primeiro os contratos marcados como conjuntos\n",
    "joint_ap.loc[mask, lista[0]] = joint_ap.loc[mask, lista[0]].fillna('Not Verified')\n",
    "\n",
    "# Em seguida preenche os demais contratos com 'Not Applicable'\n",
    "joint_ap[lista[0]] = joint_ap[lista[0]].fillna('Not Applicable')\n",
    "\n",
    "\n",
    "# A outra feature categórica, 'sec_app_earliest_cr_line' (lista[1]),\n",
    "# refere-se à data do primeiro empréstimo tomado pelo segundo proponente.\n",
    "# Como é impossível essa estimação, toma-se a data do contrato em pleito\n",
    "# como data de primeiro empréstimo.\n",
    "valores = emprestimos.loc[mask][joint_ap.loc[mask, lista[1]].isnull()]['issue_d'].values\n",
    "indices = emprestimos.loc[mask][joint_ap.loc[mask, lista[1]].isnull()]['issue_d'].index.to_list()\n",
    "joint_ap.loc[indices, lista[1]] = valores\n",
    "\n",
    "# O restante das NaNs substitui-se por 'Not Applicable'\n",
    "joint_ap[lista[1]] = joint_ap[lista[1]].fillna('Not Applicable')\n",
    "\n",
    "\n",
    "# Em seguida, verificação dos dtypes float64\n",
    "lista = joint_ap.dtypes[joint_ap.dtypes == 'float64'].index.to_list()\n",
    "\n",
    "# Primeiro os contratos que são individuais serão preenchidos com zero\n",
    "mask = joint_ap['contrato_conjunto'] == 0\n",
    "joint_ap[mask] = joint_ap[mask].fillna(0)\n",
    "\n",
    "# Trata-se individualmente as variáveis dos contratos conjuntos\n",
    "mask = joint_ap['contrato_conjunto'] == 1\n",
    "\n",
    "# Explicação das features que necessitam ajuste\n",
    "analise_geral(lista, joint_ap)\n",
    "\n",
    "# NaNs na feature dti_joint assumem o valor de dti\n",
    "indices = joint_ap[joint_ap[lista[1]].isnull()][lista[1]].index.to_list()\n",
    "valores = emprestimos.iloc[indices]['dti'].values\n",
    "joint_ap.loc[indices, lista[1]] = valores\n",
    "\n",
    "# revol_bal_joint assume o valor de revol_bal\n",
    "indices = joint_ap[joint_ap[lista[2]].isnull()][lista[2]].index.to_list()\n",
    "valores = emprestimos.iloc[indices]['revol_bal'].values\n",
    "joint_ap.loc[indices, lista[2]] = valores\n",
    "\n",
    "# sec_app_revol_util assume o valor de revol_util\n",
    "indices = joint_ap[joint_ap[lista[8]].isnull()][lista[8]].index.to_list()\n",
    "valores = emprestimos.iloc[indices]['revol_util'].values  # existem NaNs no dataset original, depois se lida com isso\n",
    "joint_ap.loc[indices, lista[8]] = valores\n",
    "\n",
    "indices = joint_ap[joint_ap[lista[8]].isnull()][lista[8]].index.to_list() # refazendo índice, ainda ficam 53 NaNs\n",
    "lista = joint_ap.isnull().sum()[joint_ap.isnull().sum() > 53].index.to_list()\n",
    "\n",
    "# As fico ranges copia-se do mutuário principal, uma vez que é impossível estimar. Pode-se partir da\n",
    "# premissa que muito embora o segundo mutuário não seja idêntico ao primeiro eles devem possuir\n",
    "# hábitos e comportamentos semelhantes na grande maioria das vezes.\n",
    "\n",
    "idx_conj = joint_ap[joint_ap['contrato_conjunto'] == 1].index.to_list()  # armazena os índices de todos contratos conjuntos\n",
    "vazios = joint_ap.loc[idx_conj][joint_ap.loc[idx_conj, lista[0]].isnull()].index.to_list()  # filtra apenas os vazios em sec_app_fico_range_low\n",
    "joint_ap.loc[vazios, lista[0]] = emprestimos.loc[vazios, 'fico_range_low']  # registra o score do primeiro proponente também no segundo\n",
    "\n",
    "idx_conj = joint_ap[joint_ap['contrato_conjunto'] == 1].index.to_list()  # armazena os índices de todos contratos conjuntos\n",
    "vazios = joint_ap.loc[idx_conj][joint_ap.loc[idx_conj, lista[1]].isnull()].index.to_list()  # filtra apenas os vazios em sec_app_fico_range_high\n",
    "joint_ap.loc[vazios, lista[1]] = emprestimos.loc[vazios, 'fico_range_high']  # registra o score do primeiro proponente também no segundo\n",
    "\n",
    "# As demais features (com exceção de sec_app_revol_util) são variáveis discretas sobre consultas a cadastro,\n",
    "# quantidade de recuperações de dívidas, hipotecas, etc., do segundo proponente. NaNs preenchidos com zero:\n",
    "zeros = joint_ap.isnull().sum()[joint_ap.isnull().sum() > 53].index.to_list()\n",
    "joint_ap[zeros] = joint_ap[zeros].fillna(0)\n",
    "\n",
    "# Salva alterações em disco\n",
    "#joint_ap.to_parquet('data/joint_ap_wrangled.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c47753",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA WRANGLING: TRATAMENTO DAS DEMAIS FEATURES CATEGÓRICAS\n",
    "#=========================\n",
    "emprestimos = pd.read_parquet('data/emprestimos_dropado.parquet')\n",
    "dropar = ['Unnamed: 0', 'url', 'zip_code']  # features sem utilização no contexto deste estudo\n",
    "emprestimos.drop(dropar, axis=1, inplace=True)\n",
    "\n",
    "# Ajuste feature 'term' (prazo) para numérica\n",
    "emprestimos['term'] = emprestimos['term'].replace({emprestimos.loc[0, 'term']: 36, emprestimos.loc[1, 'term']: 60})\n",
    "\n",
    "# 'tax_liens' se preenche com zeros, como não tem como estimar essa informação então\n",
    "# parte-se do princípio que o tomador não tenha essa recuperação judicial\n",
    "emprestimos['tax_liens'] = emprestimos['tax_liens'].fillna(0)\n",
    "\n",
    "# As observações em 'next_pymnt_d' são todas ou liquidadas ou transferidas para prejuízo\n",
    "mask = emprestimos['next_pymnt_d'].isnull()\n",
    "#emprestimos.loc[mask, 'loan_status'].value_counts()  # caso seja necessária a verificação\n",
    "\n",
    "# Criação dos índices dos contratos e substituição dos NaNs\n",
    "pagos = emprestimos.loc[mask, 'loan_status'][emprestimos.loc[mask, 'loan_status'] == 'Fully Paid'].index.values\n",
    "pagos = emprestimos.iloc[pagos]['next_pymnt_d'].fillna('fully_paid')\n",
    "emprestimos['next_pymnt_d'] = emprestimos['next_pymnt_d'].fillna(pagos)\n",
    "\n",
    "prejuizo = emprestimos.loc[mask, 'loan_status'][emprestimos.loc[mask, 'loan_status'] == 'Charged Off'].index.values\n",
    "prejuizo = emprestimos.iloc[prejuizo]['next_pymnt_d'].fillna('charged_off')\n",
    "emprestimos['next_pymnt_d'] = emprestimos['next_pymnt_d'].fillna(prejuizo)\n",
    "\n",
    "# 'mths_since_rcnt_il': se não existe informação sobre a última concessão de crédito\n",
    "# ao tomador, infere-se que o contrato vigente foi o último na análise. Logo, fillna(-1)\n",
    "emprestimos['mths_since_rcnt_il'] = emprestimos['mths_since_rcnt_il'].fillna(-1)\n",
    "\n",
    "# 'emp_length' fillna('Unknown'), não tem como inferir tempo de emprego dos proponentes\n",
    "emprestimos['emp_length'] = emprestimos['emp_length'].fillna('Unknown')\n",
    "\n",
    "# 'earliest_cr_line' também não tem como inferir data do primeiro crédito concedido\n",
    "# ao tomador, então  utiliza-se este como referência\n",
    "mask = emprestimos['earliest_cr_line'].isnull()\n",
    "earliest = emprestimos.loc[mask, 'issue_d']\n",
    "emprestimos['earliest_cr_line'] = emprestimos['earliest_cr_line'].fillna(earliest)\n",
    "\n",
    "# 'emp_title' fillna('Unknown'), impossível inferir cargo do proponente\n",
    "emprestimos['emp_title'] = emprestimos['emp_title'].fillna('Unknown')\n",
    "\n",
    "# 'title' - nome do empréstimo. Já tem uma feature com o objetivo do empréstimo proposto ('purpose'). Pode apenas fazer uma feature nova\n",
    "# binária tipo 'empréstimo tem nome? sim/não'. Procedimento de binning aqui, as categorias mais significativas serão mantidas como estão,\n",
    "# as demais serão enquandadas como 'outros'. Utilizada representatividade > 0.65% em função de ser o limiar que não repete categorias\n",
    "# similares. Antes de qualquer processo de binning, os valores NaN são imputados como 'unknown'. (descomentar abaixo)\n",
    "\n",
    "#sem_nome = emprestimos['title'].isnull()\n",
    "#emprestimos['title'] = emprestimos['title'].fillna('Unknown')\n",
    "#relacao = emprestimos.loc[~sem_nome, 'title'].value_counts(normalize=True)\n",
    "#relacao = relacao[relacao > 0.0065].index.to_list()\n",
    "#relacao.append('Unknown')\n",
    "#nomes = emprestimos['title'].copy()\n",
    "\n",
    "# Load dos valores em 'title' já ajustados\n",
    "nomes = pd.read_parquet('data/nomes.parquet')\n",
    "emprestimos['title'] = nomes\n",
    "\n",
    "\"\"\"\n",
    "# Seção comentada para não refazer todo santo script, demora horas\n",
    "# para concluir. Dados processados já salvos em data/titles.parquet\n",
    "\n",
    "# Primeiro faz uma leitura de possíveis enquadramentos\n",
    "# de cartão de crédito (geral)\n",
    "card = []\n",
    "for obs in nomes.to_list():\n",
    "    if \"american express\" in obs.lower():\n",
    "        card.append(obs)\n",
    "    if \"card\" in obs.lower():\n",
    "        card.append(obs)\n",
    "\n",
    "# Em seguida faz a substituição dos valores de grafia diversa\n",
    "# como relacao[1]\n",
    "for obs in pd.Series(card).unique():\n",
    "    mask = nomes == obs\n",
    "    nomes.loc[mask] = relacao[1]\n",
    "\n",
    "# Segunda etapa, consolidações de débitos\n",
    "consolid = []\n",
    "for obs in nomes.to_list():\n",
    "    if \"eliminat\" in obs.lower():\n",
    "        consolid.append(obs)\n",
    "    if \"consol\" in obs.lower():\n",
    "        consolid.append(obs)\n",
    "    if \"debt\" in obs.lower():\n",
    "        consolid.append(obs)\n",
    "    if \"pay\" in obs.lower():\n",
    "        consolid.append(obs)\n",
    "    if \"bills\" in obs.lower():\n",
    "        consolid.append(obs)\n",
    "    if \"finance\" in obs.lower():\n",
    "        consolid.append(obs)\n",
    "# Substituindo os valores como relacao[0]\n",
    "for obs in pd.Series(consolid).unique():\n",
    "    mask = nomes == obs\n",
    "    nomes.loc[mask] = relacao[0]\n",
    "\n",
    "# Terceira etapa, despesas médicas e de saúde\n",
    "medic = []\n",
    "for obs in nomes.to_list():\n",
    "    if \"medic\" in obs.lower():\n",
    "        medic.append(obs)\n",
    "    if \"hospital\" in obs.lower():\n",
    "        medic.append(obs)\n",
    "    if \"health\" in obs.lower():\n",
    "        medic.append(obs)\n",
    "    if \"dentist\" in obs.lower():\n",
    "        medic.append(obs)\n",
    "# Substituindo os valores como relacao[5]\n",
    "for obs in pd.Series(medic).unique():\n",
    "    mask = nomes == obs\n",
    "    nomes.loc[mask] = relacao[5]\n",
    "\n",
    "# Quinta etapa, relativo a reforma de casa própria\n",
    "casa_reforma = []\n",
    "for obs in nomes.to_list():\n",
    "    if \"improv\" in obs.lower():\n",
    "        casa_reforma.append(obs)\n",
    "    if \"house\" in obs.lower():\n",
    "        casa_reforma.append(obs)\n",
    "    if \"kitchen\" in obs.lower():\n",
    "        casa_reforma.append(obs)\n",
    "    if \"room\" in obs.lower():\n",
    "        casa_reforma.append(obs)\n",
    "    if \"backyard\" in obs.lower():\n",
    "        casa_reforma.append(obs)\n",
    "    if \"back yard\" in obs.lower():\n",
    "        casa_reforma.append(obs)\n",
    "    if \"floor\" in obs.lower():\n",
    "        casa_reforma.append(obs)\n",
    "    if \"pool\" in obs.lower():\n",
    "        casa_reforma.append(obs)\n",
    "    if \"basement\" in obs.lower():\n",
    "        casa_reforma.append(obs)\n",
    "    if \"roof\" in obs.lower():\n",
    "        casa_reforma.append(obs)\n",
    "    if \"hot tub\" in obs.lower():\n",
    "        casa_reforma.append(obs)\n",
    "    if \"windows\" in obs.lower():\n",
    "        casa_reforma.append(obs)\n",
    "# Substituindo os valores como relacao[2]\n",
    "for obs in pd.Series(casa_reforma).unique():\n",
    "    mask = nomes == obs\n",
    "    nomes.loc[mask] = 'House improvement'\n",
    "\n",
    "# Sexta etapa, relativo a compra de imóveis\n",
    "casa_compra = []\n",
    "for obs in nomes.to_list():\n",
    "    if \"real state\" in obs.lower():\n",
    "        casa_compra.append(obs)\n",
    "    if \"property\" in obs.lower():\n",
    "        casa_compra.append(obs)\n",
    "    if \"construc\" in obs.lower():\n",
    "        casa_compra.append(obs)\n",
    "    if \"moving\" in obs.lower():\n",
    "        casa_compra.append(obs)\n",
    "    if \"apartment\" in obs.lower():\n",
    "        casa_compra.append(obs)\n",
    "    if \"home\" in obs.lower():\n",
    "        casa_compra.append(obs)\n",
    "# Substituindo os valores como relacao[2]\n",
    "for obs in pd.Series(casa_compra).unique():\n",
    "mask = nomes == obs\n",
    "    nomes.loc[mask] = 'Real Estate'\n",
    "\n",
    "# Quarta etapa, relativo a empresas e empreendimentos\n",
    "startup = []\n",
    "for obs in nomes.to_list():\n",
    "    if \"business\" in obs.lower():\n",
    "        startup.append(obs)\n",
    "    if \"personel\" in obs.lower():\n",
    "        startup.append(obs)\n",
    "    if \"startup\" in obs.lower():\n",
    "        startup.append(obs)\n",
    "    if \"start-up\" in obs.lower():\n",
    "        startup.append(obs)\n",
    "# Substituindo os valores como relacao[7]\n",
    "for obs in pd.Series(startup).unique():\n",
    "    mask = nomes == obs\n",
    "    nomes.loc[mask] = relacao[7]\n",
    "\n",
    "# Setima etapa, veículos e similares\n",
    "veiculos = []\n",
    "for obs in nomes.to_list():\n",
    "    if \"car \" in obs.lower():\n",
    "        veiculos.append(obs)\n",
    "    if \"motor\" in obs.lower():\n",
    "        veiculos.append(obs)\n",
    "    if \"bike\" in obs.lower():\n",
    "        veiculos.append(obs)\n",
    "    if \"vehicle\" in obs.lower():\n",
    "        veiculos.append(obs)\n",
    "    if \"triumph\" in obs.lower():\n",
    "        veiculos.append(obs)\n",
    "    if \"wheeler\" in obs.lower():\n",
    "        veiculos.append(obs)\n",
    "    if \"honda\" in obs.lower():\n",
    "        veiculos.append(obs)\n",
    "    if \"boat\" in obs.lower():\n",
    "        veiculos.append(obs)\n",
    "    if \"truck\" in obs.lower():\n",
    "        veiculos.append(obs)\n",
    "    if \"engine\" in obs.lower():\n",
    "        veiculos.append(obs)\n",
    "# Substituindo os valores como relacao[6]\n",
    "for obs in pd.Series(veiculos).unique():\n",
    "    mask = nomes == obs\n",
    "    nomes.loc[mask] = relacao[6]\n",
    "\n",
    "# Oitava etapa, green loans e empréstimos pessoais\n",
    "verdes = []\n",
    "for obs in nomes.to_list():\n",
    "    if \"green\" in obs.lower():\n",
    "        verdes.append(obs)\n",
    "# Substituindo os valores como relacao[6]\n",
    "for obs in pd.Series(verdes).unique():\n",
    "    mask = nomes == obs\n",
    "    nomes.loc[mask] = 'Green loan'\n",
    "\n",
    "pessoal = []\n",
    "for obs in nomes.to_list():\n",
    "    if \"personal\" in obs.lower():\n",
    "        pessoal.append(obs)\n",
    "    if \"my\" in obs.lower():\n",
    "        pessoal.append(obs)\n",
    "    if \"freedom\" in obs.lower():\n",
    "        pessoal.append(obs)\n",
    "    if \"fresh start\" in obs.lower():\n",
    "        pessoal.append(obs)\n",
    "    if \"wedding\" in obs.lower():\n",
    "        pessoal.append(obs)\n",
    "# Substituindo os valores como relacao[6]\n",
    "for obs in pd.Series(pessoal).unique():\n",
    "    mask = nomes == obs\n",
    "    nomes.loc[mask] = 'Personal Loan'\n",
    "\n",
    "# Última etapa, tudo que não for enquadramento constante em\n",
    "# 'relacao' é classificado como 'Outros'. O dataset original já\n",
    "# possui um enquandramentto 'Others', aqui opta-se por separar\n",
    "# essas classificações para evitar ruídos\n",
    "\n",
    "relacao = nomes.value_counts(normalize=True).head(8).index.to_list()\n",
    "mask = nomes.isin(relacao)\n",
    "nomes.loc[~mask] = 'Outros'\n",
    "\"\"\"\n",
    "\n",
    "# Feature last_credit_pull_d refere-se ao mês em que foi realizada a última consulta ao FICO (credito score) do cliente. Pressupõe-se\n",
    "# que pelo menos no mês de liberação do crédito tenha sido consultado.\n",
    "mask = emprestimos['last_credit_pull_d'].isnull()\n",
    "liberados = emprestimos.loc[mask, 'issue_d']\n",
    "emprestimos['last_credit_pull_d'] = emprestimos['last_credit_pull_d'].fillna(liberados)\n",
    "\n",
    "# A feature 'last_pymnt_d' refere-se ao último pagamento recebido (com ref base 09/2020).\n",
    "# Bem como a feature 'mths_since_last_delinq', que refere-se à quantidade de meses desde o último atraso.\n",
    "# Imputações baseam-se nas informações de 'loan_status':\n",
    "# [0] Charged off: 150 dias de atraso\n",
    "# [1] Issued: pelo menos 121 dias de atraso\n",
    "# [2] Late (31-120 days)\n",
    "# [3] In grace period: até 15 dias de atraso (não tem ônus)\n",
    "# [4] Does not meet the credit policy. Status: Charged Off': considera-se mesmo prazo do 'charged off'\n",
    "# [5] Late (16-30 days)\n",
    "# [6] Current: em dia, não está em atraso. \n",
    "\n",
    "pgto = emprestimos['last_pymnt_d'].isnull()\n",
    "statuses = emprestimos.loc[pgto, 'loan_status'].value_counts().index.to_list()  # pega a relação dos status possíveis\n",
    "emprestimos['last_pymnt_d'] = pd.to_datetime(emprestimos['last_pymnt_d'], format='%b-%Y')  # reformata de 'object' para data\n",
    "emprestimos['issue_d'] = pd.to_datetime(emprestimos['issue_d'], format='%b-%Y')\n",
    "mes_ref = emprestimos['last_pymnt_d'].max()  # considera-se o mês mais recente como último pagamento esperado\n",
    "\n",
    "# [0] Charged Off: -5 meses\n",
    "mask = emprestimos.loc[pgto, 'loan_status'] == statuses[0]\n",
    "idx = emprestimos.loc[pgto, 'last_pymnt_d'][mask].index.to_list()\n",
    "meses = 5\n",
    "emprestimos.loc[idx, 'last_pymnt_d'] = mes_ref - DateOffset(months=meses)\n",
    "emprestimos.loc[idx, 'mths_since_last_delinq'] = emprestimos.loc[idx, 'mths_since_last_delinq'].fillna(meses)\n",
    "\n",
    "# [1] Issued: -4 meses\n",
    "mask = emprestimos.loc[pgto, 'loan_status'] == statuses[1]\n",
    "idx = emprestimos.loc[pgto, 'last_pymnt_d'][mask].index.to_list()\n",
    "meses = 4\n",
    "emprestimos.loc[idx, 'last_pymnt_d'] = mes_ref - DateOffset(months=meses)\n",
    "emprestimos.loc[idx, 'mths_since_last_delinq'] = emprestimos.loc[idx, 'mths_since_last_delinq'].fillna(meses)\n",
    "\n",
    "# [2] Late (31-120 days): -2 meses\n",
    "mask = emprestimos.loc[pgto, 'loan_status'] == statuses[2]\n",
    "idx = emprestimos.loc[pgto, 'last_pymnt_d'][mask].index.to_list()\n",
    "meses = 2\n",
    "emprestimos.loc[idx, 'last_pymnt_d'] = mes_ref - DateOffset(months=meses)\n",
    "emprestimos.loc[idx, 'mths_since_last_delinq'] = emprestimos.loc[idx, 'mths_since_last_delinq'].fillna(meses)\n",
    "\n",
    "# [3] In Grace Period: mes_ref\n",
    "mask = emprestimos.loc[pgto, 'loan_status'] == statuses[3]\n",
    "idx = emprestimos.loc[pgto, 'last_pymnt_d'][mask].index.to_list()\n",
    "emprestimos.loc[idx, 'last_pymnt_d'] = mes_ref\n",
    "emprestimos.loc[idx, 'mths_since_last_delinq'] = emprestimos.loc[idx, 'mths_since_last_delinq'].fillna(0)\n",
    "\n",
    "# [4] Does not meet...: -5 meses\n",
    "mask = emprestimos.loc[pgto, 'loan_status'] == statuses[4]\n",
    "idx = emprestimos.loc[pgto, 'last_pymnt_d'][mask].index.to_list()\n",
    "meses = 5\n",
    "emprestimos.loc[idx, 'last_pymnt_d'] = mes_ref - DateOffset(months=meses)\n",
    "emprestimos.loc[idx, 'mths_since_last_delinq'] = emprestimos.loc[idx, 'mths_since_last_delinq'].fillna(meses)\n",
    "\n",
    "# [5] Late (16-30 days): -1 mês\n",
    "mask = emprestimos.loc[pgto, 'loan_status'] == statuses[5]\n",
    "idx = emprestimos.loc[pgto, 'last_pymnt_d'][mask].index.to_list()\n",
    "meses = 1\n",
    "emprestimos.loc[idx, 'last_pymnt_d'] = mes_ref - DateOffset(months=meses)\n",
    "emprestimos.loc[idx, 'mths_since_last_delinq'] = emprestimos.loc[idx, 'mths_since_last_delinq'].fillna(meses)\n",
    "\n",
    "# [6] Current: mes_ref\n",
    "mask = emprestimos.loc[pgto, 'loan_status'] == statuses[6]\n",
    "idx = emprestimos.loc[pgto, 'last_pymnt_d'][mask].index.to_list()\n",
    "emprestimos.loc[idx, 'last_pymnt_d'] = mes_ref\n",
    "emprestimos.loc[idx, 'mths_since_last_delinq'] = emprestimos.loc[idx, 'mths_since_last_delinq'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dbf4652",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA WRANGLING: TRATAMENTO DAS DEMAIS FEATURES NUMÉRICAS\n",
    "#=========================\n",
    "\n",
    "# Variáveis a dropar: todas com NaNs maiores que 20% e que não é possível imputar\n",
    "# valores sem contaminar o banco de dados\n",
    "dropar = ['mths_since_last_record',\n",
    "          'mths_since_last_major_derog',\n",
    "          'open_acc_6m',\n",
    "          'open_act_il',\n",
    "          'open_il_12m',\n",
    "          'open_il_24m',\n",
    "          'total_bal_il',\n",
    "          'il_util',\n",
    "          'open_rv_12m',\n",
    "          'open_rv_24m',\n",
    "          'max_bal_bc',\n",
    "          'all_util',\n",
    "          'total_cu_tl',\n",
    "          'inq_last_12m',\n",
    "          'mths_since_recent_bc_dlq',\n",
    "          'mths_since_recent_revol_delinq']\n",
    "emprestimos.drop(dropar, axis=1, inplace=True)\n",
    "\n",
    "# Verificação de cada feature\n",
    "numeros = emprestimos.dtypes[emprestimos.dtypes == 'float64'].index.values\n",
    "maiores = emprestimos[numeros].isnull().sum()[emprestimos[numeros].isnull().sum()/emprestimos.shape[0] > 0.1].index.to_list()\n",
    "menores = emprestimos[numeros].isnull().sum()[emprestimos[numeros].isnull().sum()/emprestimos.shape[0] < 0.1].index.to_list()\n",
    "#analise_nans(numeros, emprestimos)\n",
    "\n",
    "# 'pub_rec_bankruptcies', parte-se do princípio de que se o cliente não tenha informações registradas então o número é zero\n",
    "emprestimos['pub_rec_bankruptcies'] = emprestimos['pub_rec_bankruptcies'].fillna(0)\n",
    "\n",
    "# inq_fi substitui-se NaNs por zero, parte-se do princípio que o tomador não\n",
    "# fez requisições sobre finanças pessoais:\n",
    "emprestimos['inq_fi'] = emprestimos['inq_fi'].fillna(0)\n",
    "\n",
    "# status 'Fully Paid', 'In Grace Period' e 'Current' tem 0 meses desde último atraso. Nota: o tomador pode sim ter inadimplência\n",
    "# em outros contratos em outras instituições, mas trabalha-se com informações incompletas aqui\n",
    "mask = emprestimos['loan_status'].isin(['Fully Paid', 'In Grace Period', 'Current'])\n",
    "emprestimos.loc[mask, 'mths_since_last_delinq'] = emprestimos.loc[mask, 'mths_since_last_delinq'].fillna(0)\n",
    "\n",
    "# A feature 'mths_since_last_delinq' refere-se à quantidade de meses desde o último atraso.\n",
    "# Imputações baseam-se nas informações de 'loan_status':\n",
    "# [0] Charged off: 150 dias de atraso\n",
    "# [1] Issued: pelo menos 121 dias de atraso\n",
    "# [2] Late (31-120 days)\n",
    "# [3] In grace period: até 15 dias de atraso (não tem ônus)\n",
    "# [4] Does not meet the credit policy. Status: Charged Off': considera-se mesmo prazo do 'charged off'\n",
    "# [5] Late (16-30 days)\n",
    "# Default: 4 meses (ainda não entrou em charge off, que são 5 meses)\n",
    "# 'Does not meet the credit policy. Status:Fully Paid': zero, pois está pago.\n",
    "\n",
    "# [0] Charged Off: 5 meses\n",
    "mask = emprestimos['loan_status'] == statuses[0]\n",
    "meses = 5\n",
    "emprestimos.loc[mask, 'mths_since_last_delinq'] = emprestimos.loc[mask, 'mths_since_last_delinq'].fillna(meses)\n",
    "\n",
    "# [1] Issued: 4 meses\n",
    "mask = emprestimos['loan_status'] == statuses[1]\n",
    "meses = 4\n",
    "emprestimos.loc[mask, 'mths_since_last_delinq'] = emprestimos.loc[mask, 'mths_since_last_delinq'].fillna(meses)\n",
    "\n",
    "# [2] Late (31-120 days): 2 meses\n",
    "mask = emprestimos['loan_status'] == statuses[2]\n",
    "meses = 2\n",
    "emprestimos.loc[mask, 'mths_since_last_delinq'] = emprestimos.loc[mask, 'mths_since_last_delinq'].fillna(meses)\n",
    "\n",
    "# [3] In Grace Period: zero\n",
    "mask = emprestimos['loan_status'] == statuses[3]\n",
    "emprestimos.loc[mask, 'mths_since_last_delinq'] = emprestimos.loc[mask, 'mths_since_last_delinq'].fillna(0)\n",
    "\n",
    "# [4] Does not meet...: 5 meses\n",
    "mask = emprestimos['loan_status'] == statuses[4]\n",
    "meses = 5\n",
    "emprestimos.loc[mask, 'mths_since_last_delinq'] = emprestimos.loc[mask, 'mths_since_last_delinq'].fillna(meses)\n",
    "\n",
    "# [5] Late (16-30 days): 1 mês\n",
    "mask = emprestimos['loan_status'] == statuses[5]\n",
    "meses = 1\n",
    "emprestimos.loc[mask, 'mths_since_last_delinq'] = emprestimos.loc[mask, 'mths_since_last_delinq'].fillna(meses)\n",
    "\n",
    "# Default: 4 meses\n",
    "mask = emprestimos['loan_status'] == 'Default'\n",
    "meses = 4\n",
    "emprestimos.loc[mask, 'mths_since_last_delinq'] = emprestimos.loc[mask, 'mths_since_last_delinq'].fillna(meses)\n",
    "\n",
    "# 'Does not meet the credit policy. Status:Fully Paid': zero, pois está pago.\n",
    "mask = emprestimos['loan_status'] == 'Does not meet the credit policy. Status:Fully Paid'\n",
    "emprestimos.loc[mask, 'mths_since_last_delinq'] = emprestimos.loc[mask, 'mths_since_last_delinq'].fillna(0)\n",
    "\n",
    "# Reformata as observações apropriadas de object para data\n",
    "emprestimos['last_credit_pull_d']= pd.to_datetime(emprestimos['last_credit_pull_d'], format='%b-%Y')  # reformata de 'object' para data\n",
    "emprestimos['earliest_cr_line']= pd.to_datetime(emprestimos['earliest_cr_line'], format='%b-%Y')  # reformata de 'object' para data\n",
    "\n",
    "# Criação de nova variável que considera o tempo total de experiência com empréstimos\n",
    "# do proponente\n",
    "anos = (emprestimos['issue_d'].dt.year - emprestimos['earliest_cr_line'].dt.year)*12\n",
    "meses = emprestimos['issue_d'].dt.month - emprestimos['earliest_cr_line'].dt.month\n",
    "tempo_tomador = anos + meses\n",
    "emprestimos['tempo_total_tomador'] = tempo_tomador\n",
    "\n",
    "# Criação de nova variável que considera o tempo desde a última consulta ao score do proponente\n",
    "anos = (emprestimos['issue_d'].dt.year - emprestimos['last_credit_pull_d'].dt.year)*12\n",
    "meses = emprestimos['issue_d'].dt.month - emprestimos['last_credit_pull_d'].dt.month\n",
    "consulta_score = anos + meses\n",
    "emprestimos['tempo_consulta'] = consulta_score\n",
    "\n",
    "# Tudo pronto em questão de features, dropa-se as features que já cumpriram seu papel e armazena-se em disco o dataset ajustado\n",
    "dropar = ['last_pymnt_d', 'last_credit_pull_d', 'earliest_cr_line']\n",
    "emprestimos.drop(dropar, axis=1, inplace=True)\n",
    "#emprestimos.to_parquet('data/emprestimos_wrangled.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85711303",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CARREGAMENTO DOS DADOS JÁ AJUSTADOS E UNIFICAÇÃO\n",
    "#=========================\n",
    "\n",
    "# Carregamento dos arquivos parquet\n",
    "emprestimos = pd.read_parquet('data/emprestimos_wrangled.parquet')\n",
    "hard = pd.read_parquet('data/hardships_wrangled.parquet')\n",
    "joint = pd.read_parquet('data/joint_ap_wrangled.parquet')\n",
    "\n",
    "# União em um único objeto\n",
    "emprestimos = pd.concat([emprestimos, hard], axis=1)\n",
    "emprestimos = pd.concat([emprestimos, joint], axis=1)\n",
    "\n",
    "# Armazenamento em disco do objeto unificado\n",
    "#emprestimos.to_parquet('data/emprestimos_wrangled_unificado.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340072b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINIÇÃO DO TARGET, INCLUSÃO DAS TAXAS DE JUROS, ONE-HOT-ENCODING E DROPS FINAIS\n",
    "#=========================\n",
    "\n",
    "emprestimos = pd.read_parquet('data/emprestimos_wrangled_unificado.parquet')  # carrega o arquivo\n",
    "emprestimos.drop(['id', 'emp_title', 'next_pymnt_d'], axis=1, inplace=True)  # dropa features agora sem sentido\n",
    "emprestimos = emprestimos.dropna()  # dropa NaNs remanescentes\n",
    "\n",
    "# O objetivo do estudo proposto é estimar a probabilidade de um contrato não ser pago,\n",
    "# então considera-se como 'não pago' todo empréstimo que ficar em atraso acima de\n",
    "# 120 dias, quando então será considerado inadimplido e registrado como prejuízo no\n",
    "# devido tempo\n",
    "#emprestimos['loan_status'].value_counts()  # apenas para checar os status possíveis\n",
    "\n",
    "inad = ['Charged Off', 'Issued', 'Default']  # cria uma lista com os status não-pagos\n",
    "\n",
    "# Criação do target ('default'):\n",
    "mask = emprestimos['loan_status'].isin(inad)  # máscara para identificação dos contratos não-pagos\n",
    "emprestimos['default'] = 0  # criação da feature de target\n",
    "emprestimos.loc[mask, 'default'] = 1  # registro dos contratos não-pagos\n",
    "\n",
    "# Registra em 'default' a inadimplência existente seja em contrato regular ou em renegociação,\n",
    "# dropando a inadimplência específica da renegociação\n",
    "emprestimos['default'] = emprestimos[['default', 'hardship_default']].max(axis=1)\n",
    "emprestimos.drop('hardship_default', axis=1, inplace=True)\n",
    "\n",
    "\n",
    "# Inclusão das taxas de juros\n",
    "# Tratamento do arquivo com as taxas de juros\n",
    "effr = pd.read_csv('./data/EFFR.csv')\n",
    "effr['observation_date'] = pd.to_datetime(effr['observation_date'])  # transforma a informação de cronologia de object para datas\n",
    "\n",
    "mask_pos = effr['observation_date'] >= '2021-10-01'  # seleciona as datas até 2021Q3\n",
    "mask_pre = effr['observation_date'] <= '2011-07-31'  # seleciona as dadas pré ano de 2012\n",
    "dropar = np.array(effr[mask_pos | mask_pre].index)  # filtra os índices referente a essas datas em um array\n",
    "effr = effr.drop(dropar).dropna().reset_index(drop=True)  # dropa as datas selecionadas e elimina NaNs (dias como Natal e Ano-Novo, por exemplo), refazendo o índice\n",
    "\n",
    "datas = separa_datas(effr, 'observation_date')\n",
    "taxas = effr['EFFR']  # isola as taxas de juros\n",
    "effr = pd.concat([datas, taxas], axis=1)\n",
    "\n",
    "# O registro da concessão dos empréstimos contém informação apenas de mês/ano do contrato, não da data em que foi feito. Para utilização\n",
    "# de taxa de juros vigente bem como taxa futura esperada, será utilizada a média das taxas reais praticadas em cada mês.\n",
    "effr = effr.groupby(['mes_ano'])['EFFR'].mean().reset_index()  # agrega as informações por mês, informando a média\n",
    "effr['mes_ano'] = pd.to_datetime(effr['mes_ano'], format='%b-%Y')  # manipulação de object para data\n",
    "effr = effr.sort_values(by='mes_ano').reset_index(drop=True)  # ordena em função da data\n",
    "effr['mes_ano'] = separa_datas(effr, 'mes_ano')  # faz o ajuste de mês e ano novamente\n",
    "\n",
    "# O ruído é baseado nos últimos 6 períodos para a expectativa futura de 6 meses e\n",
    "# baseado nos últimos 12 períodos para a expectativa futura de 12 meses\n",
    "expec_6m = effr['EFFR'].rolling(7).mean().dropna().reset_index(drop=True)  # desloca as observações 6 períodos à frente\n",
    "expec_12m = effr['EFFR'].rolling(13).mean().dropna().reset_index(drop=True)  # desloca 12 períodos\n",
    "\n",
    "# Criação das expectativas futuras das taxas de juros com adição de ruído.\n",
    "desvio = 0.01  # pequeno ruído a se criar (ponto percentual ao ano)\n",
    "\n",
    "ruido_6m = []\n",
    "for i in range(0,len(expec_6m)):\n",
    "    temp = np.random.normal(loc=expec_6m[i], scale=desvio)  # gera um ruído aleatório ao redor da taxa real utilizando o desvio estabelecido\n",
    "    ruido_6m.append(temp)\n",
    "expec_6m = abs(pd.Series(ruido_6m, name='expec6m'))  # utiliza valores em módulo, não existem juros negativos na prática\n",
    "\n",
    "ruido_12m = []\n",
    "for i in range(0,len(expec_12m)):\n",
    "    temp = np.random.normal(loc=expec_12m[i], scale=desvio)\n",
    "    ruido_12m.append(temp)\n",
    "expec_12m = abs(pd.Series(ruido_12m, name='expec12m'))\n",
    "\n",
    "# Une as expectativas de taxas em um único dataframe\n",
    "expectativas = pd.concat([expec_6m, expec_12m], axis=1)\n",
    "\n",
    "# E une o dataframe original\n",
    "effr = pd.concat([effr, expectativas], axis=1)\n",
    "\n",
    "# Com as manipulações já feitas, seleciona-se apenas o período compreendido pelo\n",
    "# banco de dados contendo as informações dos contratos (2007 a 2018)\n",
    "effr = effr.drop(range(0,12)).dropna().reset_index(drop=True)\n",
    "\n",
    "# Para finalizar, transforma a coluna de datas de formato 'object' para data\n",
    "effr['mes_ano'] = pd.to_datetime(effr['mes_ano'], format='%b-%Y')\n",
    "\n",
    "# Une as taxas de juros ao dataset dos contratos\n",
    "emprestimos = pd.merge(right=emprestimos, left=effr, right_on='issue_d', left_on='mes_ano')\n",
    "\n",
    "# Dropa festures que já cumpriram seu propósito\n",
    "dropar = ['mes_ano', 'issue_d', 'hardship_status', 'loan_status', 'earliest_cr_line']\n",
    "emprestimos.drop(dropar, axis=1, inplace=True)\n",
    "#emprestimos.to_parquet('data/emprestimos_pre_ohe.parquet')\n",
    "\n",
    "# Se o código for executado pela primeira vez, comentar a linha abaixo (não tem nada a carregar) e descomentar a linha acima (para salvar os dados processados em disco)\n",
    "emprestimos = pd.read_parquet('data/emprestimos_pre_ohe.parquet')\n",
    "objetos = emprestimos.dtypes[emprestimos.dtypes == 'object'].index.to_list()\n",
    "\n",
    "print(f'Tamanho de \"objetos\": {len(objetos)} observações')\n",
    "ohe = OneHotEncoder(drop='first',\n",
    "                    sparse_output=False).set_output(transform='pandas')\n",
    "\n",
    "separacao = round(len(objetos)/2)  # como eu fiz várias vezes, e a quantidade de features foi alterando ao longo do tempo, assim fica mais prático de selecionar para o OHE\n",
    "\n",
    "# Fit do OHE feito em etapas em função de limitação de memória RAM\n",
    "emprestimos_ohe1 = ohe.fit_transform(emprestimos[objetos[0:separacao]])\n",
    "emprestimos_ohe1.to_parquet('data/emprestimos_ohe1.parquet')  # salva em disco\n",
    "\n",
    "emprestimos_ohe2 = ohe.fit_transform(emprestimos[objetos[separacao+1:len(objetos)-1]])\n",
    "emprestimos_ohe2.to_parquet('data/emprestimos_ohe2.parquet')  # salva em disco\n",
    "\n",
    "emprestimos_ohe = pd.concat([emprestimos_ohe1, emprestimos_ohe2], axis=1)\n",
    "emprestimos_ohe.to_parquet('data/emprestimos_ohe.parquet')\n",
    "\n",
    "#emprestimos_ohe = pd.read_parquet('data/emprestimos_ohe.parquet')  # carrega as features OHE\n",
    "emprestimos = emprestimos.drop(objetos, axis=1)  # dropa as colunas já utilizadas para OHE\n",
    "emprestimos = pd.concat([emprestimos, emprestimos_ohe], axis=1)  # une os dataframes\n",
    "emprestimos.to_parquet('data/emprestimos_pronto.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4d7a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SEPARAÇÃO DAS OBSERVAÇÕES ENTRE MODELAGEM (treino/teste) E VALIDAÇÃO (segundo teste)\n",
    "#=========================\n",
    "\n",
    "emprestimos = pd.read_parquet('data/emprestimos_pronto.parquet')\n",
    "# O dataset possui uma variável que tem um caractere inválido no nome da coluna, o erro\n",
    "# foi identificado na hora da modelagem mas é corrigido aqui\n",
    "errado = 'emp_length_< 1 year'\n",
    "emprestimos['emp_length_upto_1_year'] = emprestimos[errado]\n",
    "emprestimos.drop(errado, axis=1, inplace=True)\n",
    "\n",
    "# O banco de dados original é separado em duas partes, uma que servirá para\n",
    "# validação do modelo (15% do total) e outra que será utilizada para a modelagem\n",
    "# propriamente dita.\n",
    "modelagem, validacao = train_test_split(emprestimos, test_size=0.15, random_state=1)\n",
    "\n",
    "# Verifica se as proporções do target são congruentes\n",
    "modelagem['default'].value_counts(normalize=True)\n",
    "validacao['default'].value_counts(normalize=True)\n",
    "\n",
    "# Salva os banco de dados segregados em disco\n",
    "modelagem.to_parquet('data/modelagem.parquet')\n",
    "validacao.to_parquet('data/validacao.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a33dcc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CARREGAMENTO DOS DADOS E SEPARAÇÃO TREINO/TESTE\n",
    "#=========================\n",
    "\n",
    "\"\"\"\n",
    "# Carregamento inicial do banco de dados para treino e teste\n",
    "modelagem = pd.read_parquet('data/modelagem.parquet')\n",
    "\n",
    "# Definição das variáveis dependente e independentes, salvando em disco\n",
    "target = ['default']\n",
    "test_data = modelagem[target]\n",
    "train_data = modelagem.drop(target, axis = 1)\n",
    "\n",
    "test_data.to_parquet('data/test_data.parquet')\n",
    "train_data.to_parquet('data/train_data.parquet')\n",
    "\"\"\"\n",
    "\n",
    "# Com os dados salvos, carrega-se apenas os datasets já ajustados\n",
    "validacao = pd.read_parquet('data/validacao.parquet')\n",
    "train_data = pd.read_parquet('data/train_data.parquet')\n",
    "test_data = pd.read_parquet('data/test_data.parquet')\n",
    "\n",
    "# Train/test split\n",
    "target = ['default']\n",
    "tamanho_treino = 0.8\n",
    "treino_x, teste_x, treino_y, teste_y = train_test_split(train_data, test_data, train_size=tamanho_treino, random_state=1)\n",
    "valid_y = validacao[target]\n",
    "valid_x = validacao.drop(target, axis=1)\n",
    "del train_data, test_data, validacao  # libera memória"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba65b667",
   "metadata": {},
   "source": [
    "MÉTRICAS DE AVALIAÇÃO:\n",
    " - Accuracy: accuracy_score\n",
    " - Sensitivity: recall_score(pos_label=1)\n",
    " - Specifity: recall_score(pos_label=0)\n",
    " - Precision:  precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b81c6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### MODELO 1. BOOSTING - CatBoost (CatBoostClassifier) - R2 0.990142 teste, CV score 0.998875, R2 validação 0.990845\n",
    "from catboost import CatBoostClassifier\n",
    "# Model parameters\n",
    "nome_modelo = datetime.datetime.now().strftime(\"%Y%m%d-%H%M\")  # I like to record the inicial time for the model's name at the end\n",
    "classif_cat = CatBoostClassifier(loss_function='Logloss', # https://catboost.ai/en/docs/concepts/loss-functions-classification#usage-information\n",
    "                                 eval_metric = 'Logloss', # Logloss, AUC, MAPE, Poisson, Precision, Accuracy, R2, MedianAbsoluteError, PairAccuracy, PrecisionAt https://catboost.ai/en/docs/references/custom-metric__supported-metrics\n",
    "                                 iterations = 1000,\n",
    "                                 learning_rate = 0.01,\n",
    "                                 random_seed = 1,\n",
    "                                 bootstrap_type = 'MVS', #Bayesian (log), Bernoulli (stochastic), MVS (variance), Poisson (Poisson distribution)\n",
    "                                 bagging_temperature = 7, \n",
    "                                 depth = 10,\n",
    "                                 early_stopping_rounds = 500,\n",
    "                                 thread_count = 12,\n",
    "                                 task_type = 'CPU', \n",
    "                                 gpu_ram_part = 0.2,\n",
    "                                 target_border = 0.5, \n",
    "                                 grow_policy = 'Lossguide', # Lossguide, Depthwise, SymmetricTree\n",
    "                                 min_child_samples = 15, # default 1\n",
    "                                 max_leaves = 20, # default 31\n",
    "                                 boosting_type = 'Plain', # https://catboost.ai/en/docs/references/training-parameters/common#boosting_type\n",
    "                                 score_function = 'L2' # L2, NewtonL2\n",
    "                                 )\n",
    "\n",
    "# Model fitting\n",
    "classif_cat.fit(treino_x, treino_y,\n",
    "            eval_set = (teste_x, teste_y),\n",
    "            verbose = 100)\n",
    "\n",
    "# Cálculo de validação cruzada (avalia a robustez do modelo)\n",
    "cv_scores_cat = cross_val_score(classif_cat, treino_x, y = treino_y,\n",
    "                                       verbose = 0,\n",
    "                                       params = {'eval_set':(teste_x, teste_y), 'verbose':100}, \n",
    "                                       error_score = 'raise')\n",
    "\n",
    "## Análise da previsão\n",
    "# Cálculo das métricas com os dados de teste\n",
    "ypred_cat = classif_cat.predict(teste_x)  # previsão dos dados de teste\n",
    "score_cat_r2 = r2_score(teste_y, ypred_cat)  # cálculo de coeficiente de determinação (R2)\n",
    "roc_auc_cat = roc_auc_score(teste_y, ypred_cat)  # cálculo ROC-AUC\n",
    "acc_cat = accuracy_score(teste_y, ypred_cat)  # cálculo accuracy\n",
    "\n",
    "# Cálculo das métricas com os dados de validação\n",
    "yvalid_cat = classif_cat.predict(valid_x)  # previsão dos dados de validação\n",
    "score_cat_r2v = r2_score(valid_y, yvalid_cat)  # cálculo do coeficiente de determinação (R2)\n",
    "roc_auc_catv = roc_auc_score(valid_y, yvalid_cat)  # cálculo ROC-AUC\n",
    "acc_catv = accuracy_score(valid_y, yvalid_cat)  # cálculo accuracy\n",
    "\n",
    "print(f'Análises do Modelo CatBoost {nome_modelo}\\n')\n",
    "print(f'Score de cross-validation: {cv_scores_cat.mean():.6f}\\n')\n",
    "print('Análise do modelo com os dados de TESTE')\n",
    "print(f'Coeficiente de Determinação (R2): {score_cat_r2:.6f}')\n",
    "print(f'Valor métrica ROC-AUC: {roc_auc_cat:.6f}')\n",
    "print(f'Valor de Accuracy: {acc_cat:.6f}')\n",
    "\n",
    "print('\\nAnálise do modelo com dados de VALIDAÇÃO')\n",
    "print(f'\\nCoeficiente de Determinação (R2): {score_cat_r2_v:.6f}')\n",
    "print(f'Valor métrica ROC-AUC: {roc_auc_catv:.6f}')\n",
    "print(f'Valor de Accuracy: {acc_catv:.6f}')\n",
    "\n",
    "# Matriz de confusão\n",
    "conf_matrix = metrics.confusion_matrix(teste_y.default.values.astype('int'), ypred_cat, labels=[1, 0])\n",
    "plt.figure(figsize=(18, 18))\n",
    "sns.heatmap(conf_matrix,\n",
    "            fmt='d',\n",
    "            annot=True,\n",
    "            cmap='Oranges',\n",
    "            xticklabels=['Inadimplentes', 'Em dia'],\n",
    "            yticklabels=['Inadimplentes', 'Em dia'])\n",
    "plt.title(f'Matriz de Confusão - modelo CatBoost {nome_modelo}', fontsize=12)\n",
    "plt.xlabel('Dados de teste', fontsize=12)\n",
    "plt.ylabel('Dados previstos', fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f6e2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### MODELO 2. RANDOM FOREST - RandomForestClassifier - R2 0.981004 teste, CV 0.997701, R2 validação 0.981563\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# Model parameters\n",
    "nome_modelo = datetime.datetime.now().strftime(\"%Y%m%d-%H%M\")  # Again.\n",
    "classif_skl_rf = RandomForestClassifier(n_estimators = 1000,\n",
    "                                        criterion = 'entropy', # 'gini' default, 'entropy', 'log_loss'\n",
    "                                        max_depth = 21, # default None\n",
    "                                        min_samples_split = 6, # default 2\n",
    "                                        min_samples_leaf = 1, # default 1\n",
    "                                        max_features='sqrt', # 'sqrt' default, 'log2, None\n",
    "                                        bootstrap = True, # se 'False' usa o dataset inteiro para montar cada árvore\n",
    "                                        oob_score = False, # Utilizado se bootstrep = True, usa uma métrica para o score geral (algo tipo r2score(y_true, y_pred))\n",
    "                                        max_samples = 0.4, # usa com bootstrap = True, percentual de utilização amostral de X para treinar cada estimamdor\n",
    "                                        n_jobs = 12,\n",
    "                                        random_state = 1,\n",
    "                                        verbose = 2,\n",
    "                                        warm_start = False, # default, se True reutiliza a solução do último fit e adiciona mais estimadores ao agrupado\n",
    "                                        )\n",
    "\n",
    "# Model fitting\n",
    "classif_skl_rf.fit(treino_x, treino_y)\n",
    "\n",
    "# Model cross-validation (assessing the model's robustness)\n",
    "cv_scores_skl_rf = cross_val_score(classif_skl_rf, treino_x, y = treino_y, # estimador (usado no fit), X, y (se existente)\n",
    "                                       verbose = 100,\n",
    "                                       error_score = 'raise')\n",
    "\n",
    "## Análise da previsão\n",
    "# Cálculo das métricas com os dados de teste\n",
    "ypred_skl_rf = classif_skl_rf.predict(teste_x)  # previsão dos dados de teste\n",
    "score_skl_rf_r2 = r2_score(teste_y, ypred_skl_rf)  # cálculo de coeficiente de determinação (R2)\n",
    "roc_auc_skl_rf = roc_auc_score(teste_y, ypred_skl_rf)  # cálculo ROC-AUC\n",
    "acc_skl_rf = accuracy_score(teste_y, ypred_skl_rf)  # cálculo accuracy\n",
    "\n",
    "# Cálculo das métricas com os dados de validação\n",
    "yvalid_skl_rf = classif_skl_rf.predict(valid_x)  # previsão dos dados de validação\n",
    "score_skl_rf_r2v = r2_score(valid_y, yvalid_skl_rf)  # cálculo do coeficiente de determinação (R2)\n",
    "roc_auc_skl_rfv = roc_auc_score(valid_y, yvalid_skl_rf)  # cálculo ROC-AUC\n",
    "acc_skl_rfv = accuracy_score(valid_y, yvalid_skl_rf)  # cálculo accuracy\n",
    "\n",
    "print(f'Análises do Modelo CatBoost {nome_modelo}\\n')\n",
    "print(f'Score de cross-validation: {cv_scores_skl_rf.mean():.6f}\\n')\n",
    "print('Análise do modelo com os dados de TESTE')\n",
    "print(f'Coeficiente de Determinação (R2): {score_skl_rf_r2:.6f}')\n",
    "print(f'Valor métrica ROC-AUC: {roc_auc_skl_rf:.6f}')\n",
    "print(f'Valor de Accuracy: {acc_skl_rf:.6f}')\n",
    "\n",
    "print('\\nAnálise do modelo com dados de VALIDAÇÃO')\n",
    "print(f'\\nCoeficiente de Determinação (R2): {score_skl_rf_r2_v:.6f}')\n",
    "print(f'Valor métrica ROC-AUC: {roc_auc_skl_rfv:.6f}')\n",
    "print(f'Valor de Accuracy: {acc_skl_rfv:.6f}')\n",
    "\n",
    "# Matriz de confusão\n",
    "conf_matrix = metrics.confusion_matrix(teste_y.default.values.astype('int'), ypred_skl_rf, labels=[1, 0])\n",
    "plt.figure(figsize=(6, 6))\n",
    "sns.heatmap(conf_matrix,\n",
    "            fmt='d',\n",
    "            annot=True,\n",
    "            cmap='Oranges',\n",
    "            xticklabels=['Inadimplente', 'Em dia'],\n",
    "            yticklabels=['Inadimplente', 'Em dia'])\n",
    "plt.title(f'Matriz de confusão - modelo Random Forest {nome_modelo}', fontsize=12)\n",
    "plt.xlabel('Dados de teste', fontsize=12)\n",
    "plt.ylabel('Dados previstos', fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aaafb3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### MODELO 3. SVM - XXXXXXXXXXX - R2 0.XXXXXX teste, CV 0.XXXXXX, R2 validação 0.XXXXXX\n",
    "# Model parameters\n",
    "nome_modelo = datetime.datetime.now().strftime(\"%Y%m%d-%H%M\")\n",
    "\n",
    "\n",
    "## Análise da previsão\n",
    "# Cálculo das métricas com os dados de teste\n",
    "ypred_svm = classif_svm.predict(teste_x)  # previsão dos dados de teste\n",
    "score_svm_r2 = r2_score(teste_y, ypred_svm)  # cálculo de coeficiente de determinação (R2)\n",
    "roc_auc_svm = roc_auc_score(teste_y, ypred_svm)  # cálculo ROC-AUC\n",
    "acc_svm = accuracy_score(teste_y, ypred_svm)  # cálculo accuracy\n",
    "\n",
    "# Cálculo das métricas com os dados de validação\n",
    "yvalid_svm = classif_svm.predict(valid_x)  # previsão dos dados de validação\n",
    "score_svm_r2v = r2_score(valid_y, yvalid_svm)  # cálculo do coeficiente de determinação (R2)\n",
    "roc_auc_svmv = roc_auc_score(valid_y, yvalid_svm)  # cálculo ROC-AUC\n",
    "acc_svmv = accuracy_score(valid_y, yvalid_svm)  # cálculo accuracy\n",
    "\n",
    "print(f'Análises do Modelo SVM {nome_modelo}\\n')\n",
    "print(f'Score de cross-validation: {cv_scores_svm.mean():.6f}\\n')\n",
    "print('Análise do modelo com os dados de TESTE')\n",
    "print(f'Coeficiente de Determinação (R2): {score_svm_r2:.6f}')\n",
    "print(f'Valor métrica ROC-AUC: {roc_auc_svm:.6f}')\n",
    "print(f'Valor de Accuracy: {acc_svm:.6f}')\n",
    "\n",
    "print('\\nAnálise do modelo com dados de VALIDAÇÃO')\n",
    "print(f'\\nCoeficiente de Determinação (R2): {score_svm_r2_v:.6f}')\n",
    "print(f'Valor métrica ROC-AUC: {roc_auc_svmv:.6f}')\n",
    "print(f'Valor de Accuracy: {acc_svmv:.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5daa87",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### MODELO 4. REDE NEURAL - XXXXXXXXXXX - R2 0.XXXXXX teste, CV 0.XXXXXX, R2 validação 0.XXXXXX\n",
    "# Model parameters\n",
    "nome_modelo = datetime.datetime.now().strftime(\"%Y%m%d-%H%M\")  # Again.\n",
    "\n",
    "## Análise da previsão\n",
    "# Cálculo das métricas com os dados de teste\n",
    "ypred_nn = classif_nn.predict(teste_x)  # previsão dos dados de teste\n",
    "score_nn_r2 = r2_score(teste_y, ypred_nn)  # cálculo de coeficiente de determinação (R2)\n",
    "roc_auc_nn = roc_auc_score(teste_y, ypred_nn)  # cálculo ROC-AUC\n",
    "acc_nn = accuracy_score(teste_y, ypred_nn)  # cálculo accuracy\n",
    "\n",
    "# Cálculo das métricas com os dados de validação\n",
    "yvalid_nn = classif_nn.predict(valid_x)  # previsão dos dados de validação\n",
    "score_nn_r2v = r2_score(valid_y, yvalid_nn)  # cálculo do coeficiente de determinação (R2)\n",
    "roc_auc_nnv = roc_auc_score(valid_y, yvalid_nn)  # cálculo ROC-AUC\n",
    "acc_nnv = accuracy_score(valid_y, yvalid_nn)  # cálculo accuracy\n",
    "\n",
    "print(f'Análises do Modelo de Rede Neural {nome_modelo}\\n')\n",
    "print(f'Score de cross-validation: {cv_scores_nn.mean():.6f}\\n')\n",
    "print('Análise do modelo com os dados de TESTE')\n",
    "print(f'Coeficiente de Determinação (R2): {score_nn_r2:.6f}')\n",
    "print(f'Valor métrica ROC-AUC: {roc_auc_nn:.6f}')\n",
    "print(f'Valor de Accuracy: {acc_nn:.6f}')\n",
    "\n",
    "print('\\nAnálise do modelo com dados de VALIDAÇÃO')\n",
    "print(f'\\nCoeficiente de Determinação (R2): {score_nn_r2_v:.6f}')\n",
    "print(f'Valor métrica ROC-AUC: {roc_auc_nnv:.6f}')\n",
    "print(f'Valor de Accuracy: {acc_nnv:.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe624ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### MODELO 5. LDA - LINEAR DISCRIMINANT ANALYSIS - R2 0.XXXXXX teste, CV 0.XXXXXX, R2 validação 0.XXXXXX\n",
    "\n",
    "## Análise da previsão\n",
    "# Cálculo das métricas com os dados de teste\n",
    "ypred_lda = classif_lda.predict(teste_x)  # previsão dos dados de teste\n",
    "score_lda_r2 = r2_score(teste_y, ypred_lda)  # cálculo de coeficiente de determinação (R2)\n",
    "roc_auc_lda = roc_auc_score(teste_y, ypred_lda)  # cálculo ROC-AUC\n",
    "acc_lda = accuracy_score(teste_y, ypred_lda)  # cálculo accuracy\n",
    "#!\n",
    "# Cálculo das métricas com os dados de validação\n",
    "yvalid_lda = classif_lda.predict(valid_x)  # previsão dos dados de validação\n",
    "score_lda_r2v = r2_score(valid_y, yvalid_lda)  # cálculo do coeficiente de determinação (R2)\n",
    "roc_auc_ldav = roc_auc_score(valid_y, yvalid_lda)  # cálculo ROC-AUC\n",
    "acc_ldav = accuracy_score(valid_y, yvalid_lda)  # cálculo accuracy\n",
    "#!\n",
    "print(f'Análises do Modelo LDA {nome_modelo}\\n')\n",
    "print(f'Score de cross-validation: {cv_scores_lda.mean():.6f}\\n')\n",
    "print('Análise do modelo com os dados de TESTE')\n",
    "print(f'Coeficiente de Determinação (R2): {score_lda_r2:.6f}')\n",
    "print(f'Valor métrica ROC-AUC: {roc_auc_lda:.6f}')\n",
    "print(f'Valor de Accuracy: {acc_lda:.6f}')\n",
    "#!\n",
    "print('\\nAnálise do modelo com dados de VALIDAÇÃO')\n",
    "print(f'\\nCoeficiente de Determinação (R2): {score_lda_r2_v:.6f}')\n",
    "print(f'Valor métrica ROC-AUC: {roc_auc_ldav:.6f}')\n",
    "print(f'Valor de Accuracy: {acc_ldav:.6f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
